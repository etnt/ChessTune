from flask import Flask, request, jsonify
import chess
import chess.pgn
from transformers import GPT2LMHeadModel, AutoTokenizer
import torch
import argparse
import logging
import random
from flask_cors import CORS

app = Flask(__name__)
#CORS(app)  # This will enable CORS for all routes

# Global variables to store the model, tokenizer, and current game state
model = None
tokenizer = None
board = None

logging.basicConfig(level=logging.INFO)

def load_model(model_path):
    """
    Load the GPT-2 model and tokenizer from the specified path.

    Args:
        model_path (str): Path to the trained model.

    Global variables:
        model: The loaded GPT-2 model.
        tokenizer: The loaded tokenizer.
    """
    global model, tokenizer
    model = GPT2LMHeadModel.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained("gpt2-medium")
    tokenizer.pad_token = tokenizer.eos_token

def generate_move(num_moves=10):
    """
    Generate chess moves using the loaded GPT-2 model.

    Args:
        num_moves (int): Number of move candidates to generate. Default is 10.

    Returns:
        list: A list of legal moves generated by the model.

    Global variables:
        model: The loaded GPT-2 model.
        tokenizer: The loaded tokenizer.
        board: The current chess board state.
    """
    global model, tokenizer, board
    
    game = chess.pgn.Game.from_board(board)
    moves_str = ""
    try:
        moves_str = " ".join([board.san(move) for move in game.mainline_moves()])
    except AssertionError as e:
        logging.error(f"Error generating move history: {str(e)}")
        moves_str = board.fen()

    prompt = f"{moves_str} Next move:"
    
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True)

    with torch.no_grad():
        outputs = model.generate(
            inputs.input_ids,
            max_length=inputs.input_ids.shape[1] + 10,
            num_return_sequences=num_moves,
            do_sample=True,
            temperature=0.7,
            attention_mask=inputs.attention_mask
        )

    generated_moves = [tokenizer.decode(output[inputs.input_ids.shape[1]:], skip_special_tokens=True).strip().split()[0] for output in outputs]
    legal_moves = [move for move in generated_moves if move in [board.san(legal_move) for legal_move in board.legal_moves]]

    return legal_moves

@app.route('/init', methods=['POST'])
def init_game():
    """
    Initialize a new chess game.

    Returns:
        dict: A JSON response indicating the status of the initialization.

    Global variables:
        board: The chess board to be initialized.
    """
    global board
    board = chess.Board()
    print(f"/init : {board.fen()}")
    return jsonify({"status": "ok", "message": "New game initialized"})

@app.route('/move', methods=['POST'])
def make_move():
    """
    Apply a move to the current chess board.

    Expected JSON payload:
        {
            "move": "string"  # The move in Standard Algebraic Notation (SAN)
        }

    Returns:
        dict: A JSON response indicating the status of the move application.

    Global variables:
        board: The current chess board state.
    """
    if not request.is_json:
        return jsonify({"status": "error", "message": "Invalid JSON"}), 400
    
    move = request.json.get('move')
    if not move:
        return jsonify({"status": "error", "message": "Move not provided"}), 400
    
    global board

    print(f"/move before : {board.fen()}")
    try:
        board.push_san(move)
        print(f"/move after : {board.fen()}")
        return jsonify({"status": "ok", "message": f"Move {move} applied"})
    except ValueError:
        return jsonify({"status": "error", "message": "Invalid move"}), 400

@app.route('/get_move', methods=['GET'])
def get_ai_move():
    """
    Generate and apply an AI move to the current chess board.

    Returns:
        dict: A JSON response containing the AI's move and the new board state.

    Global variables:
        board: The current chess board state.
    """
    global board
    if board.is_game_over():
        return jsonify({"status": "game_over", "result": board.result()})
    
    generated_moves = generate_move()
    
    for move_san in generated_moves:
        try:
            move = board.parse_san(move_san)
            if move in board.legal_moves:
                board.push(move)
                return jsonify({
                    "status": "ok",
                    "move": move_san,
                    "new_fen": board.fen(en_passant='fen')
                })
        except ValueError:
            continue
    
    legal_moves = list(board.legal_moves)
    if legal_moves:
        random_move = random.choice(legal_moves)
        board.push(random_move)
        move_san = board.san(random_move)
        return jsonify({
            "status": "ok",
            "move": move_san,
            "new_fen": board.fen(en_passant='fen')
        })
    else:
        return jsonify({"status": "error", "message": "No valid move found"}), 500

@app.route('/board', methods=['GET'])
def get_board():
    """
    Get the current state of the chess board.

    Returns:
        dict: A JSON response containing the current board state in FEN notation.

    Global variables:
        board: The current chess board state.
    """
    global board
    return jsonify({"status": "ok", "fen": board.fen(en_passant='fen')})

@app.errorhandler(404)
def not_found(error):
    """
    Handle 404 Not Found errors.

    Args:
        error: The error object.

    Returns:
        dict: A JSON response indicating a 404 error.
    """
    return jsonify({"status": "error", "message": "Endpoint not found"}), 404

@app.errorhandler(Exception)
def handle_exception(e):
    """
    Handle unhandled exceptions.

    Args:
        e: The exception object.

    Returns:
        dict: A JSON response indicating an internal server error.
    """
    app.logger.error(f"Unhandled exception: {str(e)}")
    return jsonify({"status": "error", "message": "Internal server error"}), 500

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Chess server using GPT-2 model")
    parser.add_argument("--model", default="./chess_model", help="Path to the trained model (default: ./chess_model)")
    parser.add_argument("--port", type=int, default=5000, help="Port to run the server on (default: 5000)")
    
    args = parser.parse_args()

    load_model(args.model)
    app.run(debug=True, port=args.port)
